import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
import pickle
import os
import sys

# Add src directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from developmentmodel import RegionalDevelopmentModel, load_and_preprocess_data
except ImportError:
    # Try alternative import path for deployment
    import importlib.util
    spec = importlib.util.spec_from_file_location("developmentmodel", 
                                                 os.path.join(os.path.dirname(__file__), "developmentmodel.py"))
    developmentmodel = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(developmentmodel)
    RegionalDevelopmentModel = developmentmodel.RegionalDevelopmentModel
    load_and_preprocess_data = developmentmodel.load_and_preprocess_data

# Set page config
st.set_page_config(
    page_title="Regional Development Analysis",
    page_icon="üèòÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2e7d32;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #1f77b4;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_model_and_data():
    """Load and cache the model and data"""
    try:
        # Try different file paths for deployment
        possible_paths = [
            "./data/final/merged_cleaned_dataset.csv",
            "data/final/merged_cleaned_dataset.csv",
            "../data/final/merged_cleaned_dataset.csv"
        ]
        
        filepath = None
        for path in possible_paths:
            if os.path.exists(path):
                filepath = path
                break
        
        if filepath is None:
            raise FileNotFoundError("Dataset not found in any expected location")
            
        X_scaled, y_index, y_tier, df, feature_names = load_and_preprocess_data(filepath)
        
        # Train the model
        model = RegionalDevelopmentModel()
        model.train(X_scaled, y_index, y_tier)
        
        # Get feature importance
        importance_df = model.get_feature_importance(feature_names)
        
        return model, X_scaled, y_index, y_tier, df, feature_names, importance_df
    except Exception as e:
        st.error(f"Error loading data: {e}")
        return None, None, None, None, None, None, None

def main():
    # Main header
    st.markdown('<h1 class="main-header">üèòÔ∏è Regional Development Analysis System</h1>', unsafe_allow_html=True)
    st.markdown("### AI-Powered Development Index Prediction & Classification")
    
    # Load model and data
    model, X_scaled, y_index, y_tier, df, feature_names, importance_df = load_model_and_data()
    
    if model is None:
        st.error("Failed to load model and data. Please check your data files.")
        return
    
    # Sidebar navigation
    st.sidebar.title("Navigation")
    page = st.sidebar.selectbox(
        "Select Page",
        ["üè† Home", "üìä Model Performance", "üîÆ Make Predictions", "üìà Feature Analysis", "üó∫Ô∏è Regional Insights"]
    )
    
    if page == "üè† Home":
        show_home_page(df, model, X_scaled, y_index, y_tier)
    
    elif page == "üìä Model Performance":
        show_model_performance(model, X_scaled, y_index, y_tier, feature_names)
    
    elif page == "üîÆ Make Predictions":
        show_prediction_page(model, feature_names, df)
    
    elif page == "üìà Feature Analysis":
        show_feature_analysis(importance_df, df)
    
    elif page == "üó∫Ô∏è Regional Insights":
        show_regional_insights(df)

def show_home_page(df, model, X_scaled, y_index, y_tier):
    """Home page with overview"""
    st.markdown('<h2 class="sub-header">üìã Project Overview</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **üéØ Project Goal:**
        Predict regional development using AI algorithms combining:
        - **Classification** (Development Tiers: Low/Medium/High)
        - **Regression** (Development Index Score)
        - **Clustering** (Regional Grouping)
        """)
        
        st.success("""
        **üîß Algorithms Used:**
        - Random Forest Regressor
        - Random Forest Classifier  
        - K-Means Clustering
        """)
    
    with col2:
        st.markdown("**üìä Dataset Statistics:**")
        col2_1, col2_2, col2_3 = st.columns(3)
        
        with col2_1:
            st.metric("Total Regions", len(df))
        
        with col2_2:
            st.metric("Features", len(df.columns) - 3)
        
        with col2_3:
            st.metric("Data Quality", "99.1%")
    
    # Quick performance metrics
    st.markdown('<h3 class="sub-header">‚ö° Model Performance Summary</h3>', unsafe_allow_html=True)
    
    # Calculate quick metrics
    y_pred = model.regressor.predict(X_scaled)
    from sklearn.metrics import r2_score, mean_squared_error
    r2 = r2_score(y_index, y_pred)
    mse = mean_squared_error(y_index, y_pred)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("R¬≤ Score", f"{r2:.4f}", "98.7% variance explained")
    
    with col2:
        st.metric("MSE", f"{mse:.4f}", "Very low error")
    
    with col3:
        st.metric("Classification Accuracy", "99%", "Excellent tier prediction")
    
    with col4:
        st.metric("Model Status", "‚úÖ Ready", "Trained and validated")

def show_model_performance(model, X_scaled, y_index, y_tier, feature_names):
    """Model performance analysis page"""
    st.markdown('<h2 class="sub-header">üìä Model Performance Analysis</h2>', unsafe_allow_html=True)
    
    # Make predictions
    y_pred_index = model.regressor.predict(X_scaled)
    y_pred_tier = model.classifier.predict(X_scaled)
    
    # Performance metrics
    from sklearn.metrics import r2_score, mean_squared_error, classification_report, accuracy_score
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìà Regression Performance")
        r2 = r2_score(y_index, y_pred_index)
        mse = mean_squared_error(y_index, y_pred_index)
        
        st.metric("R¬≤ Score", f"{r2:.4f}")
        st.metric("Mean Squared Error", f"{mse:.6f}")
        
        # Actual vs Predicted plot
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.scatter(y_index, y_pred_index, alpha=0.6, color='blue', s=20)
        min_val = min(min(y_index), min(y_pred_index))
        max_val = max(max(y_index), max(y_pred_index))
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')
        ax.set_xlabel('Actual Development Index')
        ax.set_ylabel('Predicted Development Index')
        ax.set_title(f'Actual vs Predicted\nR¬≤ = {r2:.4f}')
        ax.legend()
        ax.grid(True, alpha=0.3)
        st.pyplot(fig)
    
    with col2:
        st.markdown("### üéØ Classification Performance")
        accuracy = accuracy_score(y_tier, y_pred_tier)
        st.metric("Accuracy", f"{accuracy:.4f}")
        
        # Classification report
        report = classification_report(y_tier, y_pred_tier, output_dict=True)
        report_df = pd.DataFrame(report).transpose()
        st.dataframe(report_df.round(4))
        
        # Confusion matrix
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_tier, y_pred_tier)
        
        fig, ax = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['High', 'Low', 'Medium'],
                   yticklabels=['High', 'Low', 'Medium'])
        ax.set_title('Confusion Matrix')
        ax.set_xlabel('Predicted')
        ax.set_ylabel('Actual')
        st.pyplot(fig)

def show_prediction_page(model, feature_names, df):
    """Interactive prediction page"""
    st.markdown('<h2 class="sub-header">üîÆ Make Development Predictions</h2>', unsafe_allow_html=True)
    
    # Two tabs: Single prediction and Batch prediction
    tab1, tab2 = st.tabs(["üèòÔ∏è Single Region", "üìÅ Batch Upload"])
    
    with tab1:
        st.markdown("### Enter Regional Infrastructure Data")
        
        # Create input form
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üè• Health Infrastructure:**")
            total_wards = st.number_input("Total Wards", min_value=1, value=10)
            health_1_2 = st.number_input("Wards with 1-2 Health Posts", min_value=0, value=3)
            health_3_4 = st.number_input("Wards with 3-4 Health Posts", min_value=0, value=2)
            health_5_9 = st.number_input("Wards with 5-9 Health Posts", min_value=0, value=1)
            health_10_plus = st.number_input("Wards with 10+ Health Posts", min_value=0, value=0)
            doctor_access = st.slider("Access to Doctor in 30 mins (%)", 0.0, 1.0, 0.7, 0.1)
            
        with col2:
            st.markdown("**üè´ Education Infrastructure:**")
            school_1_2 = st.number_input("Wards with 1-2 Schools", min_value=0, value=4)
            school_3_4 = st.number_input("Wards with 3-4 Schools", min_value=0, value=3)
            school_5_9 = st.number_input("Wards with 5-9 Schools", min_value=0, value=2)
            school_10_plus = st.number_input("Wards with 10+ Schools", min_value=0, value=1)
            
            st.markdown("**üö® Other Services:**")
            fire_access = st.slider("Access to Fire Brigade in 30 mins (%)", 0.0, 1.0, 0.5, 0.1)
            library_access = st.slider("Access to Library in 30 mins (%)", 0.0, 1.0, 0.6, 0.1)
            higher_ed_access = st.slider("Higher Education in 30 mins (%)", 0.0, 1.0, 0.4, 0.1)
        
        if st.button("üîÆ Predict Development", type="primary"):
            # Prepare input data
            input_data = prepare_single_prediction_data(
                total_wards, health_1_2, health_3_4, health_5_9, health_10_plus,
                school_1_2, school_3_4, school_5_9, school_10_plus,
                doctor_access, fire_access, library_access, higher_ed_access, df
            )
            
            # Make prediction
            if input_data is not None:
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                # Fit scaler on original data features
                original_features = df.drop(columns=['Area', 'Development_Index', 'Development_Tier']).select_dtypes(include=np.number)
                scaler.fit(original_features)
                
                input_scaled = scaler.transform(input_data)
                
                pred_index = model.regressor.predict(input_scaled)[0]
                pred_tier = model.classifier.predict(input_scaled)[0]
                cluster = model.clusterer.predict(input_scaled)[0]
                
                # Display results
                st.success("### üéâ Prediction Results")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Development Index", f"{pred_index:.4f}")
                with col2:
                    tier_color = {"Low": "üî¥", "Medium": "üü°", "High": "üü¢"}
                    st.metric("Development Tier", f"{tier_color.get(pred_tier, '‚ö™')} {pred_tier}")
                with col3:
                    st.metric("Cluster Group", f"Group {cluster + 1}")
                
                # Recommendations
                show_recommendations(pred_tier, pred_index)
    
    with tab2:
        st.markdown("### Upload CSV for Batch Predictions")
        uploaded_file = st.file_uploader("Choose a CSV file", type="csv")
        
        if uploaded_file is not None:
            try:
                batch_df = pd.read_csv(uploaded_file)
                st.write("Preview of uploaded data:")
                st.dataframe(batch_df.head())
                
                if st.button("Process Batch Predictions"):
                    # Process batch predictions here
                    st.info("Batch prediction functionality can be implemented based on your specific CSV format.")
            except Exception as e:
                st.error(f"Error reading file: {e}")

def prepare_single_prediction_data(total_wards, health_1_2, health_3_4, health_5_9, health_10_plus,
                                 school_1_2, school_3_4, school_5_9, school_10_plus,
                                 doctor_access, fire_access, library_access, higher_ed_access, df):
    """Prepare single prediction input data"""
    try:
        # Create a dataframe with the same structure as training data
        data = {
            'Total_Wards': total_wards,
            '1_2 healthpost': health_1_2 / total_wards,
            '3_4 healthpost': health_3_4 / total_wards,
            '5_9 healthpost': health_5_9 / total_wards,
            '10_plus healthpost': health_10_plus / total_wards,
            'with 1_2 school': school_1_2 / total_wards,
            'with 3_4 school': school_3_4 / total_wards,
            'with 5_9 school': school_5_9 / total_wards,
            '10_plus schools': school_10_plus / total_wards,
            'access to doctor in 30 mins': doctor_access,
            'access to firebrigade in 30 mins': fire_access,
            'access to library in 30 mins': library_access,
            'higher education in 30 mins': higher_ed_access,
            'None healthpost': max(0, (total_wards - health_1_2 - health_3_4 - health_5_9 - health_10_plus) / total_wards)
        }
        
        # Calculate derived features
        data['Health_Access'] = (
            data['1_2 healthpost'] * 1.5 + 
            data['3_4 healthpost'] * 3.5 +
            data['5_9 healthpost'] * 7 +
            data['10_plus healthpost'] * 10
        )
        
        data['Education_Access'] = (
            data['with 1_2 school'] * 1.5 + 
            data['with 3_4 school'] * 3.5 +
            data['with 5_9 school'] * 7 +
            data['10_plus schools'] * 10
        )
        
        # Add any missing features with default values
        original_features = df.drop(columns=['Area', 'Development_Index', 'Development_Tier']).select_dtypes(include=np.number)
        for col in original_features.columns:
            if col not in data:
                data[col] = 0.0
        
        # Create DataFrame and reorder columns to match training data
        input_df = pd.DataFrame([data])
        input_df = input_df.reindex(columns=original_features.columns, fill_value=0.0)
        
        return input_df
        
    except Exception as e:
        st.error(f"Error preparing prediction data: {e}")
        return None

def show_recommendations(tier, index):
    """Show development recommendations"""
    st.markdown("### üí° Development Recommendations")
    
    if tier == "Low":
        st.warning("""
        **Priority Actions for Low Development Regions:**
        - üè´ Increase educational infrastructure (schools and access)
        - üè• Improve healthcare accessibility within 30 minutes
        - üöí Establish emergency services coverage
        - üìö Build libraries and information centers
        """)
    elif tier == "Medium":
        st.info("""
        **Enhancement Strategies for Medium Development Regions:**
        - üéì Focus on higher education accessibility
        - üõ£Ô∏è Improve transportation infrastructure
        - üìã Optimize service distribution across wards
        - üèõÔ∏è Strengthen public services
        """)
    else:
        st.success("""
        **Maintenance Strategies for High Development Regions:**
        - ‚úÖ Maintain current service levels
        - üîÑ Regular infrastructure updates
        - üìä Monitor service quality
        - ü§ù Share best practices with other regions
        """)

def show_feature_analysis(importance_df, df):
    """Feature importance analysis page"""
    st.markdown('<h2 class="sub-header">üìà Feature Importance Analysis</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üéØ Most Important Features")
        
        # Interactive feature importance plot
        fig = px.bar(
            importance_df.head(15), 
            x='importance', 
            y='feature',
            orientation='h',
            title='Top 15 Feature Importance for Development Prediction',
            color='importance',
            color_continuous_scale='viridis'
        )
        fig.update_layout(height=600, yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### üìä Key Insights")
        
        top_3 = importance_df.head(3)
        for idx, row in top_3.iterrows():
            st.metric(
                f"#{idx+1} {row['feature']}", 
                f"{row['importance']:.1%}",
                help=f"Contributes {row['importance']:.1%} to model decisions"
            )
        
        st.markdown("### üìà Feature Categories")
        
        # Categorize features
        education_features = importance_df[importance_df['feature'].str.contains('school|Education|education', case=False)]
        health_features = importance_df[importance_df['feature'].str.contains('health|doctor', case=False)]
        access_features = importance_df[importance_df['feature'].str.contains('access|30 mins', case=False)]
        
        st.write(f"üéì Education: {len(education_features)} features")
        st.write(f"üè• Health: {len(health_features)} features")
        st.write(f"üöó Access: {len(access_features)} features")

def show_regional_insights(df):
    """Regional insights and data exploration"""
    st.markdown('<h2 class="sub-header">üó∫Ô∏è Regional Development Insights</h2>', unsafe_allow_html=True)
    
    # Development tier distribution
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìä Development Tier Distribution")
        tier_counts = df['Development_Tier'].value_counts()
        
        fig = px.pie(
            values=tier_counts.values, 
            names=tier_counts.index,
            title="Regional Development Distribution",
            color_discrete_map={'Low': '#ff7f7f', 'Medium': '#ffb347', 'High': '#87ceeb'}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        for tier, count in tier_counts.items():
            percentage = (count / len(df)) * 100
            st.write(f"**{tier}**: {count} regions ({percentage:.1f}%)")
    
    with col2:
        st.markdown("### üìà Development Index Distribution")
        
        fig = px.histogram(
            df, 
            x='Development_Index',
            nbins=30,
            title="Development Index Distribution",
            color_discrete_sequence=['#1f77b4']
        )
        fig.update_layout(
            xaxis_title="Development Index",
            yaxis_title="Number of Regions"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.metric("Average Development Index", f"{df['Development_Index'].mean():.4f}")
        st.metric("Standard Deviation", f"{df['Development_Index'].std():.4f}")
    
    # Top and bottom performing regions
    st.markdown("### üèÜ Regional Performance")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ü•á Top 10 Developed Regions**")
        top_regions = df.nlargest(10, 'Development_Index')[['Area', 'Development_Index', 'Development_Tier']]
        st.dataframe(top_regions, use_container_width=True)
    
    with col2:
        st.markdown("**üìà Bottom 10 Regions (Growth Potential)**")
        bottom_regions = df.nsmallest(10, 'Development_Index')[['Area', 'Development_Index', 'Development_Tier']]
        st.dataframe(bottom_regions, use_container_width=True)

if __name__ == "__main__":
    main()
